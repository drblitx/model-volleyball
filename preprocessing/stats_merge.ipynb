{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ac486dd",
   "metadata": {},
   "source": [
    "### Stats Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06bf1ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module imports\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32a6e01",
   "metadata": {},
   "source": [
    "#### Pre-Cleaning Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1cc287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting variables\n",
    "SEASON_YEAR_MAP = {\n",
    "    \"freshman\": (2016, \"FR\"),\n",
    "    \"sophomore\": (2017, \"SO\"),\n",
    "    \"junior\": (2018, \"JR\"),\n",
    "    \"senior\": (2019, \"SR\")}\n",
    "\n",
    "STAT_CATEGORIES = [\"attacking\", \"ball_handling\", \"blocking\", \"digging\", \"serve_receiving\", \"serving\"]\n",
    "\n",
    "opponent_name_corrections = {\n",
    "    \"Jackson-Reed\": \"Woodrow Wilson\"\n",
    "}\n",
    "\n",
    "opponent_slug_map = {\n",
    "    \"Alabama School for the Deaf\": \"AIDB\",\n",
    "    \"Atlanta Area School for the Deaf\": \"AASD\",\n",
    "    \"Barrie\": \"BARRIE\",\n",
    "    \"Bell\": \"BELL\",\n",
    "    \"Berman Hebrew Academy\": \"BHA\",\n",
    "    \"Bishop Ireton\": \"BIHS\",\n",
    "    \"Bishop O'Connell\": \"BOHS\",\n",
    "    \"Brookewood\": \"BW\",\n",
    "    \"Bullis\": \"BULLIS\",\n",
    "    \"Burke\": \"BURKE\",\n",
    "    \"California School for the Deaf\": \"CSDF\",\n",
    "    \"California School for the Deaf-Riverside\": \"CSDR\",\n",
    "    \"Clinton Grace Christian\": \"CGC\",\n",
    "    \"Connelly School of the Holy Child\": \"CSHC\",\n",
    "    \"Covenant Life\": \"CL\",\n",
    "    \"DC International\": \"DCI\",\n",
    "    \"E.L. Haynes\": \"HAYNES\",\n",
    "    \"Episcopal\": \"EPISCOPAL\",\n",
    "    \"Field\": \"FIELD\",\n",
    "    \"Florida School for the Deaf & Blind\": \"FSDB\",\n",
    "    \"Fredericksburg Christian\": \"FCHS\",\n",
    "    \"Friends\": \"FRIENDS\",\n",
    "    \"Georgetown Day\": \"GTD\",\n",
    "    \"Grace Christian\": \"GC\",\n",
    "    \"Grace Christian Academy\": \"GCA\",\n",
    "    \"Highland\": \"HIGHLAND\",\n",
    "    \"Indiana School for the Deaf\": \"ISD\",\n",
    "    \"Interlachen\": \"INTERLACHEN\",\n",
    "    \"Islamic Saudi Academy\": \"ISA\",\n",
    "    \"King Abdullah Academy\": \"KAA\",\n",
    "    \"Maret\": \"MARET\",\n",
    "    \"Maryland School for the Deaf\": \"MSD\",\n",
    "    \"McLean\": \"MCLEAN\",\n",
    "    \"Mississippi School for the Deaf\": \"MISD\",\n",
    "    \"Mount Airy Christian Academy\": \"MACA\",\n",
    "    \"Oakcrest\": \"OAKCREST\",\n",
    "    \"Pallotti\": \"PALLOTTI\",\n",
    "    \"Parkside\": \"PARKSIDE\",\n",
    "    \"Princess Anne\": \"PA\",\n",
    "    \"River City Science Academy\": \"RCSA\",\n",
    "    \"Riverdale Baptist\": \"RB\",\n",
    "    \"Roosevelt\": \"ROOSEVELT\",\n",
    "    \"Sandy Spring Friends\": \"SSFS\",\n",
    "    \"School Without Walls\": \"SWW\",\n",
    "    \"Seton School\": \"SETON\",\n",
    "    \"Shalom Christian Academy\": \"SCA\",\n",
    "    \"Sidwell Friends\": \"SIDWELL\",\n",
    "    \"Smith Jewish Day School\": \"SJDS\",\n",
    "    \"Spencerville Adventist Academy\": \"SAA\",\n",
    "    \"St. John's\": \"SJ\",\n",
    "    \"St. John's Catholic Prep\": \"SJCP\",\n",
    "    \"Stone Ridge School of the Sacred Heart\": \"SRSSH\",\n",
    "    \"StoneBridge\": \"SB\",\n",
    "    \"Takoma Academy\": \"TA\",\n",
    "    \"Texas School for the Deaf\": \"TSD\",\n",
    "    \"Varsity Opponent\": \"VO\",\n",
    "    \"Washington Christian Academy\": \"WCA\",\n",
    "    \"Washington International\": \"WIS\",\n",
    "    \"Woodrow Wilson\": \"WILSON\",\n",
    "}\n",
    "\n",
    "dnp_entries = [\n",
    "        (\"2016-09-24\", \"Connelly School of the Holy Child\", \"FR\"),\n",
    "        (\"2019-10-21\", \"McLean\", \"SR\"),\n",
    "        (\"2016-09-27\", \"McLean\", \"FR\"),\n",
    "        (\"2017-09-18\", \"Berman Hebrew Academy\", \"SO\"),\n",
    "        (\"2017-11-07\", \"Bell\", \"SO\"),\n",
    "        (\"2017-11-08\", \"Jackson-Reed\", \"SO\"),\n",
    "    ]\n",
    "\n",
    "rename_map = {\n",
    "        \"kills_attacking\": \"kills\",\n",
    "        \"kills_per_set_attacking\": \"kills_per_set\",\n",
    "        \"kill_pct_attacking\": \"kill_pct\",\n",
    "        \"kill_att_attacking\": \"kill_attempts\",\n",
    "        \"kill_err_attacking\": \"kill_errors\",\n",
    "        \"hit_pct_attacking\": \"hit_pct\",\n",
    "        \"assists_ball_handling\": \"assists\",\n",
    "        \"assists_per_set_ball_handling\": \"assists_per_set\",\n",
    "        \"ball_handling_att_ball_handling\": \"ball_handling_attempts\",\n",
    "        \"ball_handling_err_ball_handling\": \"ball_handling_errors\",\n",
    "        \"solo_blks_blocking\": \"solo_blocks\",\n",
    "        \"assisted_blks_blocking\": \"assisted_blocks\",\n",
    "        \"total_blks_blocking\": \"total_blocks\",\n",
    "        \"blks_per_set_blocking\": \"blocks_per_set\",\n",
    "        \"blk_err_blocking\": \"block_errors\",\n",
    "        \"digs_digging\": \"digs\",\n",
    "        \"digs_per_set_digging\": \"digs_per_set\",\n",
    "        \"dig_err_digging\": \"dig_errors\",\n",
    "        \"receiving_serve_receiving\": \"receiving\",\n",
    "        \"receiving_err_serve_receiving\": \"receiving_errors\",\n",
    "        \"receiving_per_set_serve_receiving\": \"receiving_per_set\",\n",
    "        \"aces_serving\": \"aces\",\n",
    "        \"aces_per_set_serving\": \"aces_per_set\",\n",
    "        \"ace_pct_serving\": \"ace_pct\",\n",
    "        \"serve_att_serving\": \"serve_attempts\",\n",
    "        \"serve_err_serving\": \"serve_errors\",\n",
    "        \"serve_pct_serving\": \"serve_pct\",\n",
    "        \"points_serving\": \"points\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92437cd",
   "metadata": {},
   "source": [
    "#### Cleaning Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc2ce069",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/raw\"\n",
    "OUTPUT_DIR = \"../data/cleaned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc61ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date(date_str, year):\n",
    "    if pd.isna(date_str):\n",
    "        return None\n",
    "    try:\n",
    "        parsed = datetime.strptime(date_str.strip(), \"%m/%d\")\n",
    "        return parsed.replace(year=year).strftime(\"%Y-%m-%d\")\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4013cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_opponent_name(name):\n",
    "    return opponent_name_corrections.get(name, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4398765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opponent_slug(opponent):\n",
    "    return opponent_slug_map.get(opponent, re.sub(r'[^A-Z]', '', opponent.upper())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ab636af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suffix_stat_columns(df, stat_category):\n",
    "    meta_cols = [\"match_key\", \"date\", \"opponent\", \"result\", \"sets_played\", \"season\", \"opponent_slug\"]\n",
    "    stat_cols = [col for col in df.columns if col not in meta_cols]\n",
    "    df = df.rename(columns={col: f\"{col}_{stat_category}\" for col in stat_cols})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "990ca6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_junior_stat_rows_from_schedule():\n",
    "    schedule_path = os.path.join(\"../data/schedules/season\", \"junior_schedule.csv\")\n",
    "    if not os.path.exists(schedule_path):\n",
    "        print(\"JR schedule file missing!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    schedule_df = pd.read_csv(schedule_path)\n",
    "    year, season_code = 2018, \"JR\"\n",
    "\n",
    "    schedule_df['opponent'] = schedule_df['opponent'].apply(clean_opponent_name)\n",
    "    schedule_df['date'] = schedule_df['date'].apply(lambda d: format_date(d, year))\n",
    "    schedule_df['opponent_slug'] = schedule_df['opponent'].apply(get_opponent_slug)\n",
    "    schedule_df['season'] = season_code\n",
    "\n",
    "    schedule_df[\"match_no\"] = schedule_df.groupby(\"date\").cumcount() + 1\n",
    "    schedule_df[\"match_key\"] = (\n",
    "        schedule_df[\"season\"]\n",
    "        + \"_\" + schedule_df[\"date\"].str[5:]\n",
    "        + \"_\" + schedule_df[\"opponent_slug\"].str.replace(r'\\W+', '', regex=True)\n",
    "        + \"_\" + schedule_df[\"match_no\"].astype(str)\n",
    "    )\n",
    "\n",
    "    def combine_result(row):\n",
    "        if pd.notna(row[\"result\"]) and pd.notna(row[\"set_result\"]):\n",
    "            return f\"{row['result']} {row['set_result']}\"\n",
    "        return pd.NA\n",
    "\n",
    "    schedule_df[\"result\"] = schedule_df.apply(combine_result, axis=1)\n",
    "\n",
    "    # derive sets_played from set_result\n",
    "    def extract_sets_played(set_result):\n",
    "        try:\n",
    "            if isinstance(set_result, str) and \"-\" in set_result:\n",
    "                a, b = map(int, set_result.strip().split(\"-\"))\n",
    "                return a + b\n",
    "        except:\n",
    "            pass\n",
    "        return pd.NA\n",
    "\n",
    "    schedule_df[\"sets_played\"] = schedule_df[\"set_result\"].apply(extract_sets_played)\n",
    "\n",
    "    # manual override - injured game, but DID play 1 set (player twisted my ankle as i landed after a hit)\n",
    "    schedule_df.loc[schedule_df[\"match_key\"] == \"JR_09-27_BOHS_1\", \"sets_played\"] = 1\n",
    "\n",
    "    return schedule_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c747fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_column_types(df):\n",
    "    int_columns = [\n",
    "        \"sets_played\", \"kills_attacking\", \"kill_att_attacking\", \"kill_err_attacking\",\n",
    "        \"assists_ball_handling\", \"ball_handling_att_ball_handling\", \"ball_handling_err_ball_handling\",\n",
    "        \"solo_blks_blocking\", \"assisted_blks_blocking\", \"total_blks_blocking\", \"blk_err_blocking\",\n",
    "        \"digs_digging\", \"dig_err_digging\",\n",
    "        \"receiving_serve_receiving\", \"receiving_err_serve_receiving\",\n",
    "        \"aces_serving\", \"serve_att_serving\", \"serve_err_serving\", \"points_serving\"\n",
    "    ]\n",
    "\n",
    "    float_columns = [\n",
    "        \"kills_per_set_attacking\", \"kill_pct_attacking\", \"hit_pct_attacking\",\n",
    "        \"assists_per_set_ball_handling\",\n",
    "        \"blks_per_set_blocking\",\n",
    "        \"digs_per_set_digging\",\n",
    "        \"receiving_per_set_serve_receiving\",\n",
    "        \"aces_per_set_serving\", \"ace_pct_serving\",\n",
    "        \"serve_pct_serving\"\n",
    "    ]\n",
    "\n",
    "    for col in int_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"Int64\")\n",
    "    for col in float_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(float)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22fb472",
   "metadata": {},
   "source": [
    "#### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eef36d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_stats():\n",
    "    all_seasons_merged = []\n",
    "\n",
    "    # merge FR/SO/SR with match_key already in files\n",
    "    for season_folder in SEASON_YEAR_MAP:\n",
    "        year, season_code = SEASON_YEAR_MAP[season_folder]\n",
    "        season_path = os.path.join(DATA_DIR, season_folder)\n",
    "        print(f\"processing {season_folder} ({season_code}, {year})...\")\n",
    "\n",
    "        merged_dfs = []\n",
    "\n",
    "        for stat_category in STAT_CATEGORIES:\n",
    "            file_path = os.path.join(season_path, f\"{stat_category}.csv\")\n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                if \"match_key\" not in df.columns:\n",
    "                    print(f\"ERROR: {file_path} missing 'match_key' column.\")\n",
    "                    continue\n",
    "\n",
    "                df[\"season\"] = season_code\n",
    "                df = suffix_stat_columns(df, stat_category)\n",
    "                df = df.set_index(\"match_key\")\n",
    "\n",
    "                if merged_dfs:\n",
    "                    meta_cols = {\"date\", \"opponent\", \"result\", \"sets_played\", \"season\", \"opponent_slug\"}\n",
    "                    df = df.drop(columns=[col for col in meta_cols if col in df.columns], errors=\"ignore\")\n",
    "\n",
    "                merged_dfs.append(df)\n",
    "            else:\n",
    "                print(f\"missing: {file_path}\")\n",
    "\n",
    "        if merged_dfs:\n",
    "            season_merged = pd.concat(merged_dfs, axis=1, join=\"outer\").reset_index()\n",
    "            all_seasons_merged.append(season_merged)\n",
    "\n",
    "            out_path = os.path.join(OUTPUT_DIR, f\"{season_folder}_stats_merged.csv\")\n",
    "\n",
    "            def fix_date_with_year_row(row):\n",
    "                year_map = {\"FR\": 2016, \"SO\": 2017, \"JR\": 2018, \"SR\": 2019}\n",
    "                try:\n",
    "                    date_str = row[\"date\"]\n",
    "                    year = year_map.get(row[\"season\"])\n",
    "                    if pd.isna(date_str) or pd.isna(year):\n",
    "                        return pd.NA\n",
    "                    dt = datetime.strptime(date_str.strip(), \"%m/%d\") if len(date_str.strip()) <= 5 else \\\n",
    "                        datetime.strptime(date_str.strip(), \"%Y-%m-%d\")\n",
    "                    return dt.replace(year=year).strftime(\"%Y-%m-%d\")\n",
    "                except Exception:\n",
    "                    return pd.NA\n",
    "\n",
    "            season_merged[\"date\"] = season_merged.apply(fix_date_with_year_row, axis=1)\n",
    "\n",
    "            final_cols = [\n",
    "                \"match_key\", \"date\", \"result\", \"opponent\", \"sets_played\",\n",
    "                \"kills_attacking\", \"kills_per_set_attacking\", \"kill_pct_attacking\", \n",
    "                \"kill_att_attacking\", \"kill_err_attacking\", \"hit_pct_attacking\",\n",
    "                \"season\",\n",
    "                \"assists_ball_handling\", \"assists_per_set_ball_handling\", \n",
    "                \"ball_handling_att_ball_handling\", \"ball_handling_err_ball_handling\",\n",
    "                \"solo_blks_blocking\", \"assisted_blks_blocking\", \"total_blks_blocking\", \n",
    "                \"blks_per_set_blocking\", \"blk_err_blocking\",\n",
    "                \"digs_digging\", \"dig_err_digging\", \"digs_per_set_digging\",\n",
    "                \"receiving_serve_receiving\", \"receiving_err_serve_receiving\", \n",
    "                \"receiving_per_set_serve_receiving\",\n",
    "                \"aces_serving\", \"aces_per_set_serving\", \"ace_pct_serving\", \n",
    "                \"serve_att_serving\", \"serve_err_serving\", \"serve_pct_serving\", \n",
    "                \"points_serving\",\n",
    "            ]\n",
    "\n",
    "            for col in final_cols:\n",
    "                if col not in season_merged.columns:\n",
    "                    season_merged[col] = pd.NA\n",
    "            season_merged = season_merged[[col for col in final_cols if col in season_merged.columns]]\n",
    "            season_merged = enforce_column_types(season_merged)\n",
    "\n",
    "            season_merged.to_csv(out_path, index=False)\n",
    "            print(f\"Saved: {out_path}\")\n",
    "\n",
    "    # JR placeholder rows (no stats)\n",
    "    jr_df = create_junior_stat_rows_from_schedule()\n",
    "    if not jr_df.empty:\n",
    "        schedule_meta_cols = {\n",
    "            \"set_scores\", \"set_result\", \"set_count\", \"set_diff\", \"location\",\n",
    "            \"is_conference\", \"is_playoffs\", \"is_tournament\", \"is_championship\",\n",
    "            \"maxpreps\", \"h_a_n\"\n",
    "        }\n",
    "        jr_df = jr_df.drop(columns=[col for col in schedule_meta_cols if col in jr_df.columns], errors=\"ignore\")\n",
    "        jr_df = jr_df.drop(columns=[\"match_no\"], errors=\"ignore\")\n",
    "\n",
    "        # fill stat columns w/ 0 or NA\n",
    "        all_columns = set().union(*(df.columns for df in all_seasons_merged))\n",
    "        for col in all_columns:\n",
    "            if col not in jr_df.columns:\n",
    "                jr_df[col] = 0 if col.endswith(tuple(STAT_CATEGORIES)) else pd.NA\n",
    "\n",
    "        all_seasons_merged.append(jr_df)\n",
    "        print(\"Added junior schedule-based placeholder stats\")\n",
    "\n",
    "    # combine all into master_df\n",
    "    master_df = pd.concat(all_seasons_merged, ignore_index=True)\n",
    "\n",
    "    # DNP placeholders\n",
    "    dnp_entries = [\n",
    "        (\"2016-09-24\", \"Connelly School of the Holy Child\", \"FR\"),\n",
    "        (\"2019-10-21\", \"McLean\", \"SR\"),\n",
    "        (\"2016-09-27\", \"McLean\", \"FR\"),\n",
    "        (\"2017-09-18\", \"Berman Hebrew Academy\", \"SO\"),\n",
    "        (\"2017-11-07\", \"Bell\", \"SO\"),\n",
    "        (\"2017-11-08\", \"Jackson-Reed\", \"SO\"),\n",
    "    ]\n",
    "\n",
    "    stat_columns = [\n",
    "        col for col in master_df.columns\n",
    "        if col not in {\"match_key\", \"date\", \"opponent\", \"season\", \"opponent_slug\", \"result\"}\n",
    "    ]\n",
    "\n",
    "    dnp_rows = []\n",
    "    for date_str, opponent, season_code in dnp_entries:\n",
    "        opponent_clean = clean_opponent_name(opponent)\n",
    "        opponent_slug = get_opponent_slug(opponent_clean)\n",
    "        match_key = f\"{season_code}_{date_str[5:]}_{opponent_slug}_1\"\n",
    "\n",
    "        row = {\n",
    "            \"match_key\": match_key,\n",
    "            \"date\": date_str,\n",
    "            \"opponent\": opponent_clean,\n",
    "            \"season\": season_code,\n",
    "            \"opponent_slug\": opponent_slug,\n",
    "            \"result\": pd.NA,\n",
    "        }\n",
    "        for col in stat_columns:\n",
    "            row[col] = pd.NA\n",
    "\n",
    "        dnp_rows.append(row)\n",
    "\n",
    "    dnp_df = pd.DataFrame(dnp_rows)\n",
    "    for col in master_df.columns:\n",
    "        if col not in dnp_df.columns:\n",
    "            dnp_df[col] = pd.NA\n",
    "    dnp_df = dnp_df[master_df.columns]\n",
    "    master_df = pd.concat([master_df, dnp_df], ignore_index=True)\n",
    "    print(f\"ADDED {len(dnp_df)} DNP placeholder rows\")\n",
    "\n",
    "    SEASON_SORT_ORDER = {\"FR\": 1, \"SO\": 2, \"JR\": 3, \"SR\": 4}\n",
    "    master_df[\"season_order\"] = master_df[\"season\"].map(SEASON_SORT_ORDER)\n",
    "    master_df = master_df.sort_values(by=[\"season_order\", \"date\"]).drop(columns=[\"season_order\"])\n",
    "\n",
    "    final_cols = [\n",
    "        \"season\", \"match_key\", \"date\", \"result\", \"opponent\", \"sets_played\",\n",
    "\n",
    "        \"kills_attacking\", \"kills_per_set_attacking\", \"kill_pct_attacking\", \n",
    "        \"kill_att_attacking\", \"kill_err_attacking\", \"hit_pct_attacking\",\n",
    "\n",
    "        \"assists_ball_handling\", \"assists_per_set_ball_handling\", \n",
    "        \"ball_handling_att_ball_handling\", \"ball_handling_err_ball_handling\",\n",
    "\n",
    "        \"solo_blks_blocking\", \"assisted_blks_blocking\", \"total_blks_blocking\", \n",
    "        \"blks_per_set_blocking\", \"blk_err_blocking\",\n",
    "\n",
    "        \"digs_digging\", \"dig_err_digging\", \"digs_per_set_digging\",\n",
    "\n",
    "        \"receiving_serve_receiving\", \"receiving_err_serve_receiving\", \n",
    "        \"receiving_per_set_serve_receiving\",\n",
    "\n",
    "        \"aces_serving\", \"aces_per_set_serving\", \"ace_pct_serving\", \n",
    "        \"serve_att_serving\", \"serve_err_serving\", \"serve_pct_serving\", \n",
    "        \"points_serving\",\n",
    "    ]\n",
    "\n",
    "    for col in final_cols:\n",
    "        if col not in master_df.columns:\n",
    "            master_df[col] = pd.NA\n",
    "\n",
    "    master_df = master_df[[col for col in final_cols if col in master_df.columns]]\n",
    "    master_df = enforce_column_types(master_df)\n",
    "\n",
    "    master_df = master_df.drop_duplicates(subset=\"match_key\", keep=\"first\")\n",
    "\n",
    "    master_df = master_df.rename(columns=rename_map)\n",
    "\n",
    "    master_path = os.path.join(OUTPUT_DIR, \"all_stats_merged.csv\")\n",
    "    master_df.to_csv(master_path, index=False)\n",
    "    print(f\"SAVED master file: {master_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99ecf783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing freshman (FR, 2016)...\n",
      "Saved: ../data/cleaned/freshman_stats_merged.csv\n",
      "processing sophomore (SO, 2017)...\n",
      "Saved: ../data/cleaned/sophomore_stats_merged.csv\n",
      "processing junior (JR, 2018)...\n",
      "missing: ../data/raw/junior/attacking.csv\n",
      "missing: ../data/raw/junior/ball_handling.csv\n",
      "missing: ../data/raw/junior/blocking.csv\n",
      "missing: ../data/raw/junior/digging.csv\n",
      "missing: ../data/raw/junior/serve_receiving.csv\n",
      "missing: ../data/raw/junior/serving.csv\n",
      "processing senior (SR, 2019)...\n",
      "Saved: ../data/cleaned/senior_stats_merged.csv\n",
      "Added junior schedule-based placeholder stats\n",
      "ADDED 6 DNP placeholder rows\n",
      "SAVED master file: ../data/cleaned/all_stats_merged.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ql/b4r9tk_920vb9yf7_6r1bptw0000gn/T/ipykernel_81174/3854513026.py:142: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  master_df = pd.concat([master_df, dnp_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "merge_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "school",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
